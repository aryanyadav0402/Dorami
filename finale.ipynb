{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NER REQ.\n",
    "import spacy\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "from spacy.tokens import Span\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model_price_senti = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "#INTENT REQ.\n",
    "#import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras.backend as K\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras import Model\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "import pickle  \n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Layer\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import sklearn\n",
    "\n",
    "#QnA\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model1 = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "#Action Code\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_label = {\"price_senti\":\"\\w+[\\s]\\w+[\\s][Rr][\\s]?[Ss][\\.]?[\\s]?\\d*[,]?\\d*\",\n",
    "             \"price_range\":\"[Rr][\\s]?[Ss][\\.]?[\\s]?\\d*[,]?\\d*[\\s]?[t|a]?[o|n]?[-|d]?[\\s]?[Rr][\\s]?[Ss][\\.]?[\\s]?\\d*[,]?\\d*\",\n",
    "             \"weight_senti\":\"\\w+[\\s]\\w+[\\s]\\w+\\d*[\\.]?\\d*[\\s][Kk][Gg|Ii][Ll]?[Ll]?[Oo]?[Gg]?[Rr]?[Aa]?[Mm]?[Ss]?\",\n",
    "             \"weight_range\":\"\\d*[\\.]?\\d*[\\s][Kk][Gg|Ii][Ll]?[Ll]?[Oo]?[Gg]?[Rr]?[Aa]?[Mm]?[Ss]?[\\s]?[t|a]?[o|n]?[-|d]?[\\s]?\\d*[\\.]?\\d*[\\s][Kk][Gg|Ii][Ll]?[Ll]?[Oo]?[Gg]?[Rr]?[Aa]?[Mm]?[Ss]?\",\n",
    "             \"size_senti\":\"\\w+[\\s]\\w+[\\s]\\w+\\d*[\\.]?\\d*[\\s][I|i][N|n][C|c][H|h][e|E]?[s|S]?\",\n",
    "             \"size_range\":\"\\d*[\\.]?\\d*[\\s][I|i][N|n][C|c][H|h][e|E]?[s|S]?[\\s]?[t|a]?[o|n]?[-|d]?[\\s]?\\d*[\\.]?\\d*[\\s][I|i][N|n][C|c][H|h][e|E]?[s|S]?\",\n",
    "             \"ram_senti\":\"\\w+[\\s]\\w+[\\s]\\w+\\d*[\\.]?\\d*[\\s][Gg][Bb|Ii][Gg]?[Ss|Aa]?[Bb]?[Ii|Yy]?[Tt]?[Ee]?[Ss]?\",\n",
    "             \"ram_range\":\"\\d*[Gg][Bb|Ii][Gg]?[Ss|Aa]?[Bb]?[Ii|Yy]?[Tt]?[Ee]?[Ss]?[\\s]?[t|a]?[o|n]?[-|d]?[\\s]?\\d*[\\s][Gg][Bb|Ii][Gg]?[Ss|Aa]?[Bb]?[Ii|Yy]?[Tt]?[Ee]?[Ss]?\"\n",
    "             }\n",
    "\n",
    "def classify_query_category(query,ent_label):\n",
    "    regex_nlp = pickle.load(open(\"regex_nlp.pkl\",\"rb\"))\n",
    "    doc_reg = regex_nlp(query)\n",
    "    \n",
    "    def cosine(u, v):\n",
    "        return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "    number_ent_query = []\n",
    "    query_ents = []\n",
    "\n",
    "    for ent in doc_reg.ents:\n",
    "      if ent.label_ == ent_label:\n",
    "        number_ent_query.append(ent.text)\n",
    "    \n",
    "    if(len(number_ent_query)==1):\n",
    "      pattern_query = {\"label\":str(str(ent_label)+\"_senti\"), \"pattern\": pat_label[str(ent_label+\"_senti\")]}\n",
    "      label = str(ent_label+\"_senti\")\n",
    "    elif(len(number_ent_query)!=1) :\n",
    "      pattern_query = {\"label\":str(str(ent_label)+\"_range\"), \"pattern\": pat_label[str(ent_label+\"_range\")]}\n",
    "      label = str(ent_label+\"_range\")\n",
    "        \n",
    "    original_ents = list(doc_reg.ents)\n",
    "    \n",
    "    mwt_ents = []\n",
    "    \n",
    "    for match in re.finditer(pattern_query[\"pattern\"], doc_reg.text):\n",
    "        start, end = match.span()\n",
    "        span = doc_reg.char_span(start, end)\n",
    "        if span is not None:\n",
    "            mwt_ents.append((span.start, span.end, span.text))\n",
    "            \n",
    "#     s = match.start()\n",
    "#     e = match.end()\n",
    "    \n",
    "#     print('String match: \"%s\" at %d:%d' % (text[s:e], s, e))\n",
    "    \n",
    "    for ent in mwt_ents:\n",
    "        start, end, name = ent\n",
    "        per_ent = Span(doc_reg, start, end, label)\n",
    "        original_ents.append(per_ent)\n",
    "        \n",
    "#     print(mwt_ents)\n",
    "    ent_text_4_comparsion = str(mwt_ents[0][2])\n",
    "        \n",
    "#     for ent in original_ents:\n",
    "#          print (\"Entity text:\",ent.text,\"|| Entity label:\", ent.label_)\n",
    "    \n",
    "    text_query_above = str(\"higher than\")\n",
    "    text_query_below = str(\"lower than\")\n",
    "    text_query_around = str(\"nearly around\")\n",
    "    sentences = [text_query_above,text_query_below,text_query_around]\n",
    "    sim_values = []\n",
    "    embedding = model_price_senti.encode(sentences)\n",
    "    queryyy = str(ent_text_4_comparsion)\n",
    "    query_vec = model_price_senti.encode([queryyy])[0]\n",
    "    for sent in sentences:\n",
    "        sim = cosine(query_vec, model_price_senti.encode([sent])[0])\n",
    "        sim_values.append(sim)\n",
    "    if(len(number_ent_query)==1):\n",
    "        if max(sim_values) == sim_values[0]:\n",
    "            sim_class = str(ent_label+\"_above\")\n",
    "        elif max(sim_values) == sim_values[1]:\n",
    "            sim_class = str(ent_label+\"_below\")\n",
    "        elif max(sim_values) == sim_values[2]:\n",
    "            sim_class = str(ent_label+\"_around\")\n",
    "    else:\n",
    "        sim_class = str(ent_label+\"_range\")\n",
    "    return sim_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_query_ents(query):\n",
    "    regex_nlp = pickle.load(open(\"regex_nlp.pkl\",\"rb\"))\n",
    "    ents_list = [\"price\",\"size\",\"weight\",\"ram\"]\n",
    "    doc_reg = regex_nlp(str(query))\n",
    "    query_ents = []\n",
    "    for ent in doc_reg.ents:\n",
    "            query_ents.append((ent.text, ent.start_char, ent.end_char, ent.label_))\n",
    "#     for ent in doc_reg.ents:\n",
    "#         if ent.label_ == ent_label:\n",
    "#             num_ent_queries.append(ent.text)\n",
    "    for entity in ents_list:\n",
    "        num_ent_queries = []\n",
    "        for ent in doc_reg.ents:\n",
    "            if ent.label_ == entity:\n",
    "                num_ent_queries.append((ent.text, ent.start_char, ent.end_char, ent.label_))\n",
    "        if(len(num_ent_queries)!=0):\n",
    "            query_ents.append((classify_query_category(query,entity), 0, 0, str(entity+\"_category\")))\n",
    "            \n",
    "#         print(\"Entity_text - \",ent.text,\"=> Entity_class - \", ent.label_)\n",
    "#     print(non_price_ents)\n",
    "    return query_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 1 µs, total: 10 µs\n",
      "Wall time: 14.1 µs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_entities(user_input, visualize = False):\n",
    "    # Loading it in\n",
    "    laptop_nlp = pickle.load(open(\"laptop_big_nlp.pkl\", \"rb\"))\n",
    "   \n",
    "    doc = laptop_nlp(user_input)\n",
    "    extracted_entities = []\n",
    "    ents = list_query_ents(user_input)\n",
    "\n",
    "    # These are the objects you can take out\n",
    "    for ent in doc.ents:\n",
    "        if ent.text == '.':\n",
    "            pass\n",
    "        else:\n",
    "            extracted_entities.append((ent.text, ent.start_char, ent.end_char, ent.label_))\n",
    "    for i in ents:\n",
    "        extracted_entities.append(i)\n",
    "        \n",
    "    # If you want to visualize\n",
    "    # if visualize == True:\n",
    "    #     # Visualizing with displaCy how the document had it's entity tagged (runs a server)\n",
    "    #     colors = {\"product_type\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}\n",
    "    #     options = {\"ents\": [\"product_type\"], \"colors\": colors}\n",
    "    #     html = displacy.render(doc, style = 'ent', options = options)\n",
    "    #     display(HTML(html));\n",
    "    #     displacy.serve(doc, style=\"ent\", options=options)\n",
    "    #     displacy.serve(doc, style=\"ent\")\n",
    "    return extracted_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#INTENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = 'https://tfhub.dev/google/universal-sentence-encoder-large/4'\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.load(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 512)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "norm_layer (Lambda)          (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 157,120\n",
      "Trainable params: 156,608\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_text1 = Input(shape=(512,))\n",
    "x = Dense(256, activation='relu')(input_text1)\n",
    "x = Dropout(0.4)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "dense_layer = Dense(128, name='dense_layer')(x)\n",
    "norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer')(dense_layer)\n",
    "\n",
    "model=Model(inputs=[input_text1], outputs=norm_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for anchor, positive and negative images\n",
    "in_a = Input(shape=(512,))\n",
    "in_p = Input(shape=(512,))\n",
    "in_n = Input(shape=(512,))\n",
    "\n",
    "# Output for anchor, positive and negative embedding vectors\n",
    "# The nn4_small model instance is shared (Siamese network)\n",
    "emb_a = model(in_a)\n",
    "emb_p = model(in_p)\n",
    "emb_n = model(in_n)\n",
    "\n",
    "class TripletLossLayer(Layer):\n",
    "    def __init__(self, alpha, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def triplet_loss(self, inputs):\n",
    "        a, p, n = inputs\n",
    "        p_dist = K.sum(K.square(a-p), axis=-1)\n",
    "        n_dist = K.sum(K.square(a-n), axis=-1)\n",
    "        return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)\n",
    "        return loss\n",
    "\n",
    "# Layer that computes the triplet loss from anchor, positive and negative embedding vectors\n",
    "triplet_loss_layer = TripletLossLayer(alpha=0.4, name='triplet_loss_layer')([emb_a, emb_p, emb_n])\n",
    "\n",
    "# Model that can be trained with anchor, positive negative images\n",
    "nn4_small2_train = Model([in_a, in_p, in_n], triplet_loss_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(unique_train_label,map_train_label_indices):\n",
    "      label_l, label_r = np.random.choice(unique_train_label, 2, replace=False)\n",
    "      a, p = np.random.choice(map_train_label_indices[label_l],2, replace=False)\n",
    "      n = np.random.choice(map_train_label_indices[label_r])\n",
    "      return a, p, n\n",
    "\n",
    "def get_triplets_batch(k,train_set,unique_train_label,map_train_label_indices,embed):\n",
    "\n",
    "    while True:\n",
    "      idxs_a, idxs_p, idxs_n = [], [], []\n",
    "      for _ in range(k):\n",
    "          a, p, n = get_triplets(unique_train_label,map_train_label_indices)\n",
    "          idxs_a.append(a)\n",
    "          idxs_p.append(p)\n",
    "          idxs_n.append(n)\n",
    "\n",
    "      a=train_set.iloc[idxs_a].values.tolist()\n",
    "      b=train_set.iloc[idxs_p].values.tolist()\n",
    "      c=train_set.iloc[idxs_n].values.tolist()\n",
    "\n",
    "      a = embed(a)\n",
    "      p = embed(b)\n",
    "      n = embed(c)\n",
    "        # return train_set[idxs_a], train_set[idxs_p], train_set[idxs_n]\n",
    "      yield [a,p,n], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe0e82a17b8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn4_small2_train.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'svc.sav'\n",
    "# load the model from disk\n",
    "svc = pickle.load(open(filename, 'rb'))\n",
    "#result = svc.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataset 1 - Sheet1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Data we want to encode.\n",
    "sentences = df[\"Question\"]\n",
    "\n",
    "#Encoding the Data\n",
    "##embedding = model1.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embedding.pickle', 'rb') as pkl:\n",
    "    embedding = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining cosine similarity function\n",
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using similarity values to answer queries\n",
    "\n",
    "def Q_A(query):\n",
    "    # while(True):\n",
    "      #query = input(\"User: \")\n",
    "    query_vec = model1.encode([query])[0]\n",
    "    sim = []\n",
    "    for sent in sentences:\n",
    "        sim.append(cosine(query_vec, model1.encode([sent])[0]))\n",
    "    if(max(sim)>0.4):\n",
    "        return df['Answer'][sim.index(max(sim))]\n",
    "    else:\n",
    "        return 'Sorry, I could not understand.'\n",
    "#     print(res)\n",
    "      #     continue\n",
    "      # if(df['Answer'][sim.index(max(sim))]==\"Thank you! See you again.\"):\n",
    "      #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res=dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product</th>\n",
       "      <th>title</th>\n",
       "      <th>title_link</th>\n",
       "      <th>image</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>ram</th>\n",
       "      <th>weight</th>\n",
       "      <th>Additional specs</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hp</td>\n",
       "      <td>hp pavilion ryzen 5 hexa core 5600h</td>\n",
       "      <td>hp pavilion ryzen 5 hexa core 5600h - (8 gb/51...</td>\n",
       "      <td>https://www.flipkart.com/hp-pavilion-ryzen-5-h...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹55,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>1.98 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shadow Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asus</td>\n",
       "      <td>asus tuf gaming a17 ryzen 7 octa core 4800h</td>\n",
       "      <td>asus tuf gaming a17 ryzen 7 octa core 4800h - ...</td>\n",
       "      <td>https://www.flipkart.com/asus-tuf-gaming-a17-r...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/l...</td>\n",
       "      <td>₹73,990</td>\n",
       "      <td>17.3 inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.60 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graphite Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acer</td>\n",
       "      <td>acer aspire 7 core i5 10th gen</td>\n",
       "      <td>acer aspire 7 core i5 10th gen - (8 gb/512 gb ...</td>\n",
       "      <td>https://www.flipkart.com/acer-aspire-7-core-i5...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹52,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>2.15 Kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dell</td>\n",
       "      <td>dell g15 ryzen 5 hexa core 5600h</td>\n",
       "      <td>dell g15 ryzen 5 hexa core 5600h - (8 gb/512 g...</td>\n",
       "      <td>https://www.flipkart.com/dell-g15-ryzen-5-hexa...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/l...</td>\n",
       "      <td>₹73,990</td>\n",
       "      <td>15.6 Inch</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>2.4 kg</td>\n",
       "      <td>With MS Office</td>\n",
       "      <td>Phantom Grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acer</td>\n",
       "      <td>acer nitro 5 ryzen 7 octa core 5800h</td>\n",
       "      <td>acer nitro 5 ryzen 7 octa core 5800h - (16 gb/...</td>\n",
       "      <td>https://www.flipkart.com/acer-nitro-5-ryzen-7-...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹94,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.4 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>msi</td>\n",
       "      <td>msi bravo ryzen 5 hexa core 5600h</td>\n",
       "      <td>msi bravo ryzen 5 hexa core 5600h - (8 gb/512 ...</td>\n",
       "      <td>https://www.flipkart.com/msi-bravo-ryzen-5-hex...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹54,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>2.35 Kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>msi</td>\n",
       "      <td>msi gf63 thin core i5 9th gen</td>\n",
       "      <td>msi gf63 thin core i5 9th gen - (8 gb/512 gb s...</td>\n",
       "      <td>https://www.flipkart.com/msi-gf63-thin-core-i5...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹57,999</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>1.86 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acer</td>\n",
       "      <td>acer aspire 7 ryzen 5 hexa core 5500u</td>\n",
       "      <td>acer aspire 7 ryzen 5 hexa core 5500u - (8 gb/...</td>\n",
       "      <td>https://www.flipkart.com/acer-aspire-7-ryzen-5...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹54,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>2.15 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lenovo</td>\n",
       "      <td>lenovo ideapad gaming 3 core i5 10th gen</td>\n",
       "      <td>lenovo ideapad gaming 3 core i5 10th gen - (8 ...</td>\n",
       "      <td>https://www.flipkart.com/lenovo-ideapad-gaming...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹53,490</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>2.2 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Onyx Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>asus</td>\n",
       "      <td>asus vivobook gaming core i7 10th gen</td>\n",
       "      <td>asus vivobook gaming core i7 10th gen - (16 gb...</td>\n",
       "      <td>https://www.flipkart.com/asus-vivobook-gaming-...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹64,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.14 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Star Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>msi</td>\n",
       "      <td>msi gf65 thin core i7 10th gen</td>\n",
       "      <td>msi gf65 thin core i7 10th gen - (16 gb/1 tb s...</td>\n",
       "      <td>https://www.flipkart.com/msi-gf65-thin-core-i7...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹89,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>1.86 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>asus</td>\n",
       "      <td>asus tuf gaming f17 core i7 11th gen</td>\n",
       "      <td>asus tuf gaming f17 core i7 11th gen - (16 gb/...</td>\n",
       "      <td>https://www.flipkart.com/asus-tuf-gaming-f17-c...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/l...</td>\n",
       "      <td>₹87,990</td>\n",
       "      <td>17.3 inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.60 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graphite Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hp</td>\n",
       "      <td>hp pavilion gaming core i5 11th gen</td>\n",
       "      <td>hp pavilion gaming core i5 11th gen - (8 gb/1 ...</td>\n",
       "      <td>https://www.flipkart.com/hp-pavilion-gaming-co...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹65,990</td>\n",
       "      <td>15.6 inches</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>2.28 kg</td>\n",
       "      <td>With MS Office</td>\n",
       "      <td>Shadow Black &amp; Ultra Violet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lenovo</td>\n",
       "      <td>lenovo ideapad gaming 3 core i5 11th gen</td>\n",
       "      <td>lenovo ideapad gaming 3 core i5 11th gen - (8 ...</td>\n",
       "      <td>https://www.flipkart.com/lenovo-ideapad-gaming...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹57,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>2.25 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shadow Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hp</td>\n",
       "      <td>hp omen core i7 11th gen</td>\n",
       "      <td>hp omen core i7 11th gen - (16 gb/1 tb ssd/win...</td>\n",
       "      <td>https://www.flipkart.com/hp-omen-core-i7-11th-...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹1,71,990</td>\n",
       "      <td>16.1 inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.32 kg</td>\n",
       "      <td>With MS Office</td>\n",
       "      <td>Shadow Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>msi</td>\n",
       "      <td>msi alpha 15 ryzen 7 octa core 5800h</td>\n",
       "      <td>msi alpha 15 ryzen 7 octa core 5800h - (16 gb/...</td>\n",
       "      <td>https://www.flipkart.com/msi-alpha-15-ryzen-7-...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹92,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.35 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>acer</td>\n",
       "      <td>acer predator helios 300 core i7 11th gen</td>\n",
       "      <td>acer predator helios 300 core i7 11th gen - (1...</td>\n",
       "      <td>https://www.flipkart.com/acer-predator-helios-...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹1,12,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.3 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abyssal Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>msi</td>\n",
       "      <td>msi katana gf66 core i7 11th gen</td>\n",
       "      <td>msi katana gf66 core i7 11th gen - (16 gb/1 tb...</td>\n",
       "      <td>https://www.flipkart.com/msi-katana-gf66-core-...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹91,490</td>\n",
       "      <td>15.6 inches</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.25 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>asus</td>\n",
       "      <td>asus rog flow x13 ryzen 7 octa core 5800hs</td>\n",
       "      <td>asus rog flow x13 ryzen 7 octa core 5800hs - (...</td>\n",
       "      <td>https://www.flipkart.com/asus-rog-flow-x13-ryz...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹99,990</td>\n",
       "      <td>13.4 inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>1.30 kg</td>\n",
       "      <td>With MS Office</td>\n",
       "      <td>Off Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dell</td>\n",
       "      <td>dell inspiron 5518 core i5 11th gen</td>\n",
       "      <td>dell inspiron 5518 core i5 11th gen - (16 gb/5...</td>\n",
       "      <td>https://www.flipkart.com/dell-inspiron-5518-co...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹70,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>1.65 kg</td>\n",
       "      <td>With MS Office</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lenovo</td>\n",
       "      <td>lenovo legion y540 core i5 9th gen</td>\n",
       "      <td>lenovo legion y540 core i5 9th gen - (8 gb/512...</td>\n",
       "      <td>https://www.flipkart.com/lenovo-legion-y540-co...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹69,999</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>2.1 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raven Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hp</td>\n",
       "      <td>hp 430 g8 core i5 11th gen</td>\n",
       "      <td>hp 430 g8 core i5 11th gen - (8 gb/512 gb ssd/...</td>\n",
       "      <td>https://www.flipkart.com/hp-430-g8-core-i5-11t...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹93,000</td>\n",
       "      <td>13.3 inch</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>2.15 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pike Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dell</td>\n",
       "      <td>dell inspiron 15 7000 core i7 7th gen</td>\n",
       "      <td>dell inspiron 15 7000 core i7 7th gen - (8 gb/...</td>\n",
       "      <td>https://www.flipkart.com/dell-inspiron-15-7000...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/j...</td>\n",
       "      <td>₹77,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>2.62 kg</td>\n",
       "      <td>With MS Office</td>\n",
       "      <td>Matt Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>msi</td>\n",
       "      <td>msi pulse gl66 core i7 11th gen</td>\n",
       "      <td>msi pulse gl66 core i7 11th gen - (16 gb/1 tb ...</td>\n",
       "      <td>https://www.flipkart.com/msi-pulse-gl66-core-i...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹1,09,990</td>\n",
       "      <td>15.6 Inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.25 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>msi</td>\n",
       "      <td>msi gp65 leopard core i7 10th gen</td>\n",
       "      <td>msi gp65 leopard core i7 10th gen - (16 gb/1 t...</td>\n",
       "      <td>https://www.flipkart.com/msi-gp65-leopard-core...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹1,09,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.33 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black&amp;Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>acer</td>\n",
       "      <td>acer predator helios 300 core i7 12th gen</td>\n",
       "      <td>acer predator helios 300 core i7 12th gen - (1...</td>\n",
       "      <td>https://www.flipkart.com/acer-predator-helios-...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/l...</td>\n",
       "      <td>₹1,74,990</td>\n",
       "      <td>15.6 Inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.6 KG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abyssal Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>msi</td>\n",
       "      <td>msi gp66 leopard core i7 11th gen</td>\n",
       "      <td>msi gp66 leopard core i7 11th gen - (16 gb/1 t...</td>\n",
       "      <td>https://www.flipkart.com/msi-gp66-leopard-core...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/l...</td>\n",
       "      <td>₹1,49,990</td>\n",
       "      <td>15.6 inches</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.9 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dell</td>\n",
       "      <td>dell core i5 11th gen</td>\n",
       "      <td>dell core i5 11th gen - (16 gb/512 gb ssd/wind...</td>\n",
       "      <td>https://www.flipkart.com/dell-core-i5-11th-gen...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹85,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.65 Kg</td>\n",
       "      <td>With MS Office</td>\n",
       "      <td>Dark Shadow Grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lenovo</td>\n",
       "      <td>lenovo ideapad gaming 3 ryzen 5 hexa core 4600h</td>\n",
       "      <td>lenovo ideapad gaming 3 ryzen 5 hexa core 4600...</td>\n",
       "      <td>https://www.flipkart.com/lenovo-ideapad-gaming...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹63,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>8 GB</td>\n",
       "      <td>2.2 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Onyx Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>hp</td>\n",
       "      <td>hp omen ryzen 7 octa core 4800h</td>\n",
       "      <td>hp omen ryzen 7 octa core 4800h - (16 gb/512 g...</td>\n",
       "      <td>https://www.flipkart.com/hp-omen-ryzen-7-octa-...</td>\n",
       "      <td>https://rukminim1.flixcart.com/image/612/612/k...</td>\n",
       "      <td>₹89,990</td>\n",
       "      <td>15.6 inch</td>\n",
       "      <td>16 GB</td>\n",
       "      <td>2.37 kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mica Silver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     brand                                           product  \\\n",
       "0       hp              hp pavilion ryzen 5 hexa core 5600h    \n",
       "1     asus      asus tuf gaming a17 ryzen 7 octa core 4800h    \n",
       "2     acer                   acer aspire 7 core i5 10th gen    \n",
       "3     dell                 dell g15 ryzen 5 hexa core 5600h    \n",
       "4     acer             acer nitro 5 ryzen 7 octa core 5800h    \n",
       "5      msi                msi bravo ryzen 5 hexa core 5600h    \n",
       "6      msi                    msi gf63 thin core i5 9th gen    \n",
       "7     acer            acer aspire 7 ryzen 5 hexa core 5500u    \n",
       "8   lenovo         lenovo ideapad gaming 3 core i5 10th gen    \n",
       "9     asus            asus vivobook gaming core i7 10th gen    \n",
       "10     msi                   msi gf65 thin core i7 10th gen    \n",
       "11    asus             asus tuf gaming f17 core i7 11th gen    \n",
       "12      hp              hp pavilion gaming core i5 11th gen    \n",
       "13  lenovo         lenovo ideapad gaming 3 core i5 11th gen    \n",
       "14      hp                         hp omen core i7 11th gen    \n",
       "15     msi             msi alpha 15 ryzen 7 octa core 5800h    \n",
       "16    acer        acer predator helios 300 core i7 11th gen    \n",
       "17     msi                 msi katana gf66 core i7 11th gen    \n",
       "18    asus       asus rog flow x13 ryzen 7 octa core 5800hs    \n",
       "19    dell              dell inspiron 5518 core i5 11th gen    \n",
       "20  lenovo               lenovo legion y540 core i5 9th gen    \n",
       "21      hp                       hp 430 g8 core i5 11th gen    \n",
       "22    dell            dell inspiron 15 7000 core i7 7th gen    \n",
       "23     msi                  msi pulse gl66 core i7 11th gen    \n",
       "24     msi                msi gp65 leopard core i7 10th gen    \n",
       "25    acer        acer predator helios 300 core i7 12th gen    \n",
       "26     msi                msi gp66 leopard core i7 11th gen    \n",
       "27    dell                            dell core i5 11th gen    \n",
       "28  lenovo  lenovo ideapad gaming 3 ryzen 5 hexa core 4600h    \n",
       "29      hp                  hp omen ryzen 7 octa core 4800h    \n",
       "\n",
       "                                                title  \\\n",
       "0   hp pavilion ryzen 5 hexa core 5600h - (8 gb/51...   \n",
       "1   asus tuf gaming a17 ryzen 7 octa core 4800h - ...   \n",
       "2   acer aspire 7 core i5 10th gen - (8 gb/512 gb ...   \n",
       "3   dell g15 ryzen 5 hexa core 5600h - (8 gb/512 g...   \n",
       "4   acer nitro 5 ryzen 7 octa core 5800h - (16 gb/...   \n",
       "5   msi bravo ryzen 5 hexa core 5600h - (8 gb/512 ...   \n",
       "6   msi gf63 thin core i5 9th gen - (8 gb/512 gb s...   \n",
       "7   acer aspire 7 ryzen 5 hexa core 5500u - (8 gb/...   \n",
       "8   lenovo ideapad gaming 3 core i5 10th gen - (8 ...   \n",
       "9   asus vivobook gaming core i7 10th gen - (16 gb...   \n",
       "10  msi gf65 thin core i7 10th gen - (16 gb/1 tb s...   \n",
       "11  asus tuf gaming f17 core i7 11th gen - (16 gb/...   \n",
       "12  hp pavilion gaming core i5 11th gen - (8 gb/1 ...   \n",
       "13  lenovo ideapad gaming 3 core i5 11th gen - (8 ...   \n",
       "14  hp omen core i7 11th gen - (16 gb/1 tb ssd/win...   \n",
       "15  msi alpha 15 ryzen 7 octa core 5800h - (16 gb/...   \n",
       "16  acer predator helios 300 core i7 11th gen - (1...   \n",
       "17  msi katana gf66 core i7 11th gen - (16 gb/1 tb...   \n",
       "18  asus rog flow x13 ryzen 7 octa core 5800hs - (...   \n",
       "19  dell inspiron 5518 core i5 11th gen - (16 gb/5...   \n",
       "20  lenovo legion y540 core i5 9th gen - (8 gb/512...   \n",
       "21  hp 430 g8 core i5 11th gen - (8 gb/512 gb ssd/...   \n",
       "22  dell inspiron 15 7000 core i7 7th gen - (8 gb/...   \n",
       "23  msi pulse gl66 core i7 11th gen - (16 gb/1 tb ...   \n",
       "24  msi gp65 leopard core i7 10th gen - (16 gb/1 t...   \n",
       "25  acer predator helios 300 core i7 12th gen - (1...   \n",
       "26  msi gp66 leopard core i7 11th gen - (16 gb/1 t...   \n",
       "27  dell core i5 11th gen - (16 gb/512 gb ssd/wind...   \n",
       "28  lenovo ideapad gaming 3 ryzen 5 hexa core 4600...   \n",
       "29  hp omen ryzen 7 octa core 4800h - (16 gb/512 g...   \n",
       "\n",
       "                                           title_link  \\\n",
       "0   https://www.flipkart.com/hp-pavilion-ryzen-5-h...   \n",
       "1   https://www.flipkart.com/asus-tuf-gaming-a17-r...   \n",
       "2   https://www.flipkart.com/acer-aspire-7-core-i5...   \n",
       "3   https://www.flipkart.com/dell-g15-ryzen-5-hexa...   \n",
       "4   https://www.flipkart.com/acer-nitro-5-ryzen-7-...   \n",
       "5   https://www.flipkart.com/msi-bravo-ryzen-5-hex...   \n",
       "6   https://www.flipkart.com/msi-gf63-thin-core-i5...   \n",
       "7   https://www.flipkart.com/acer-aspire-7-ryzen-5...   \n",
       "8   https://www.flipkart.com/lenovo-ideapad-gaming...   \n",
       "9   https://www.flipkart.com/asus-vivobook-gaming-...   \n",
       "10  https://www.flipkart.com/msi-gf65-thin-core-i7...   \n",
       "11  https://www.flipkart.com/asus-tuf-gaming-f17-c...   \n",
       "12  https://www.flipkart.com/hp-pavilion-gaming-co...   \n",
       "13  https://www.flipkart.com/lenovo-ideapad-gaming...   \n",
       "14  https://www.flipkart.com/hp-omen-core-i7-11th-...   \n",
       "15  https://www.flipkart.com/msi-alpha-15-ryzen-7-...   \n",
       "16  https://www.flipkart.com/acer-predator-helios-...   \n",
       "17  https://www.flipkart.com/msi-katana-gf66-core-...   \n",
       "18  https://www.flipkart.com/asus-rog-flow-x13-ryz...   \n",
       "19  https://www.flipkart.com/dell-inspiron-5518-co...   \n",
       "20  https://www.flipkart.com/lenovo-legion-y540-co...   \n",
       "21  https://www.flipkart.com/hp-430-g8-core-i5-11t...   \n",
       "22  https://www.flipkart.com/dell-inspiron-15-7000...   \n",
       "23  https://www.flipkart.com/msi-pulse-gl66-core-i...   \n",
       "24  https://www.flipkart.com/msi-gp65-leopard-core...   \n",
       "25  https://www.flipkart.com/acer-predator-helios-...   \n",
       "26  https://www.flipkart.com/msi-gp66-leopard-core...   \n",
       "27  https://www.flipkart.com/dell-core-i5-11th-gen...   \n",
       "28  https://www.flipkart.com/lenovo-ideapad-gaming...   \n",
       "29  https://www.flipkart.com/hp-omen-ryzen-7-octa-...   \n",
       "\n",
       "                                                image      price         size  \\\n",
       "0   https://rukminim1.flixcart.com/image/612/612/k...    ₹55,990    15.6 inch   \n",
       "1   https://rukminim1.flixcart.com/image/612/612/l...    ₹73,990    17.3 inch   \n",
       "2   https://rukminim1.flixcart.com/image/612/612/k...    ₹52,990    15.6 inch   \n",
       "3   https://rukminim1.flixcart.com/image/612/612/l...    ₹73,990    15.6 Inch   \n",
       "4   https://rukminim1.flixcart.com/image/612/612/k...    ₹94,990    15.6 inch   \n",
       "5   https://rukminim1.flixcart.com/image/612/612/k...    ₹54,990    15.6 inch   \n",
       "6   https://rukminim1.flixcart.com/image/612/612/k...    ₹57,999    15.6 inch   \n",
       "7   https://rukminim1.flixcart.com/image/612/612/k...    ₹54,990    15.6 inch   \n",
       "8   https://rukminim1.flixcart.com/image/612/612/k...    ₹53,490    15.6 inch   \n",
       "9   https://rukminim1.flixcart.com/image/612/612/k...    ₹64,990    15.6 inch   \n",
       "10  https://rukminim1.flixcart.com/image/612/612/k...    ₹89,990    15.6 inch   \n",
       "11  https://rukminim1.flixcart.com/image/612/612/l...    ₹87,990    17.3 inch   \n",
       "12  https://rukminim1.flixcart.com/image/612/612/k...    ₹65,990  15.6 inches   \n",
       "13  https://rukminim1.flixcart.com/image/612/612/k...    ₹57,990    15.6 inch   \n",
       "14  https://rukminim1.flixcart.com/image/612/612/k...  ₹1,71,990    16.1 inch   \n",
       "15  https://rukminim1.flixcart.com/image/612/612/k...    ₹92,990    15.6 inch   \n",
       "16  https://rukminim1.flixcart.com/image/612/612/k...  ₹1,12,990    15.6 inch   \n",
       "17  https://rukminim1.flixcart.com/image/612/612/k...    ₹91,490  15.6 inches   \n",
       "18  https://rukminim1.flixcart.com/image/612/612/k...    ₹99,990    13.4 inch   \n",
       "19  https://rukminim1.flixcart.com/image/612/612/k...    ₹70,990    15.6 inch   \n",
       "20  https://rukminim1.flixcart.com/image/612/612/k...    ₹69,999    15.6 inch   \n",
       "21  https://rukminim1.flixcart.com/image/612/612/k...    ₹93,000    13.3 inch   \n",
       "22  https://rukminim1.flixcart.com/image/612/612/j...    ₹77,990    15.6 inch   \n",
       "23  https://rukminim1.flixcart.com/image/612/612/k...  ₹1,09,990    15.6 Inch   \n",
       "24  https://rukminim1.flixcart.com/image/612/612/k...  ₹1,09,990    15.6 inch   \n",
       "25  https://rukminim1.flixcart.com/image/612/612/l...  ₹1,74,990    15.6 Inch   \n",
       "26  https://rukminim1.flixcart.com/image/612/612/l...  ₹1,49,990  15.6 inches   \n",
       "27  https://rukminim1.flixcart.com/image/612/612/k...    ₹85,990    15.6 inch   \n",
       "28  https://rukminim1.flixcart.com/image/612/612/k...    ₹63,990    15.6 inch   \n",
       "29  https://rukminim1.flixcart.com/image/612/612/k...    ₹89,990    15.6 inch   \n",
       "\n",
       "      ram   weight Additional specs                        color  \n",
       "0    8 GB  1.98 kg              NaN                 Shadow Black  \n",
       "1   16 GB  2.60 kg              NaN               Graphite Black  \n",
       "2    8 GB  2.15 Kg              NaN                        Black  \n",
       "3    8 GB   2.4 kg   With MS Office                 Phantom Grey  \n",
       "4   16 GB   2.4 kg              NaN                        Black  \n",
       "5    8 GB  2.35 Kg              NaN                        Black  \n",
       "6    8 GB  1.86 kg              NaN                        Black  \n",
       "7    8 GB  2.15 kg              NaN                        Black  \n",
       "8    8 GB   2.2 kg              NaN                   Onyx Black  \n",
       "9   16 GB  2.14 kg              NaN                   Star Black  \n",
       "10  16 GB  1.86 kg              NaN                        Black  \n",
       "11  16 GB  2.60 kg              NaN               Graphite Black  \n",
       "12   8 GB  2.28 kg   With MS Office  Shadow Black & Ultra Violet  \n",
       "13   8 GB  2.25 kg              NaN                 Shadow Black  \n",
       "14  16 GB  2.32 kg   With MS Office                 Shadow Black  \n",
       "15  16 GB  2.35 kg              NaN                        Black  \n",
       "16  16 GB   2.3 kg              NaN                Abyssal Black  \n",
       "17  16 GB  2.25 kg              NaN                        Black  \n",
       "18  16 GB  1.30 kg   With MS Office                    Off Black  \n",
       "19  16 GB  1.65 kg   With MS Office                       Silver  \n",
       "20   8 GB   2.1 kg              NaN                  Raven Black  \n",
       "21   8 GB  2.15 kg              NaN                  Pike Silver  \n",
       "22   8 GB  2.62 kg   With MS Office                   Matt Black  \n",
       "23  16 GB  2.25 kg              NaN                         Gray  \n",
       "24  16 GB  2.33 kg              NaN                 Black&Silver  \n",
       "25  16 GB   2.6 KG              NaN                Abyssal Black  \n",
       "26  16 GB   2.9 kg              NaN                        Black  \n",
       "27  16 GB  2.65 Kg   With MS Office             Dark Shadow Grey  \n",
       "28   8 GB   2.2 kg              NaN                   Onyx Black  \n",
       "29  16 GB  2.37 kg              NaN                  Mica Silver  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflist = pd.read_csv('prod_gaming_laptops - flipkart-scraper_8077.csv')\n",
    "dflist.title = dflist.title.map(lambda x: x.lower())\n",
    "dflist.insert(0, 'product', dflist.title.map(lambda x: x.split('-')[0]))\n",
    "dflist.insert(0, 'brand', dflist.title.map(lambda x: x.split()[0].lower()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intents_ent(uq):\n",
    "    user_query1 = model.predict(np.array(embed(np.array(pd.Series(uq).values.tolist()))['outputs']))\n",
    "    intent = svc.predict(user_query1)\n",
    "    entities = [(entity[0].lower(), entity[3].lower()) for entity in extract_entities(uq)]\n",
    "    tups = entities\n",
    "    dictionary = {}\n",
    "    entity_dict = Convert(tups, dictionary)\n",
    "\n",
    "    return intent, entity_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert(tup, di):\n",
    "    for b, a in tup:\n",
    "        di.setdefault(a, []).append(b)\n",
    "    return di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for finding the specific product(s) from the database\n",
    "def sql_search(entity_dict):\n",
    "    # df2 = df[df['title'].str.contains(entities[])\n",
    "    value1 = list(entity_dict.values())[0]\n",
    "    Bool = dflist['title'].str.contains(value1[0])\n",
    "\n",
    "#     print(entity_dict)\n",
    "    for key, value in entity_dict.items():\n",
    "      if key == 'ram':\n",
    "        Bool1 = dflist['title'].str.contains(value[0] + \"/\") \n",
    "#         Bool1 = dflist['title'].str.contains(value[0] + \"/\") | dflist['specs'].str.contains(value[0])\n",
    "      else:\n",
    "        Bool1 = dflist['title'].str.contains(value[0])\n",
    "#         Bool1 = dflist['title'].str.contains(value[0]) | dflist['specs'].str.contains(value[0])\n",
    "      Bool1 = (Bool & Bool1)\n",
    "      Bool = Bool1\n",
    "    \n",
    "    df2 = dflist[Bool]\n",
    "    return df2\n",
    "    # output = 'Dorami: These are all the'\n",
    "    # for key in entity_dict.keys():\n",
    "    #   output += ' ' + entity_dict[key][0]\n",
    "  \n",
    "    # output += ' in our catalogue. You can choose any one of them or even give me more specifications that you want so I can narrow down the results for you!'\n",
    "    # print(output, df2.title, sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to capture missing entities\n",
    "def missing_entity(missing_entity, product_type, entity_dict):\n",
    "    \n",
    "    a = \"missing_ent\"\n",
    "    past_entity_dict = entity_dict.copy()\n",
    "    if '_' in missing_entity:\n",
    "        \n",
    "        return 'Is there any specific {} in which you want the {} or anything will do?'.format(' '.join(missing_entity.split('_')), product_type)\n",
    "    else:\n",
    "\n",
    "        return 'Is there any specific {} in which you want the {} or anything will do?'.format(missing_entity, product_type)\n",
    "#      print('Dorami: Is there any specific {} in which you want the {} or anything will do?'.format(missing_entity, product_type))\n",
    "#       p = 'Dorami: Is there any specific {} in which you want the {} or anything will do?'\n",
    "#       res.append(p)\n",
    "#       return res\n",
    "    #user_query = input('User: ')\n",
    "    \n",
    "    # capturing intents and entities\n",
    "    \n",
    "\n",
    "#     intent, missing_entity_dict = intents_ent(user_query)\n",
    "#     print(intent, missing_entity_dict)\n",
    "\n",
    "#     if intent == 'no':\n",
    "#       return dict()\n",
    "#     else:\n",
    "#       return missing_entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_search(entity_dict):\n",
    "    # df2 = df[df['title'].str.contains(entities[])\n",
    "    value1 = list(entity_dict.values())[0][0]\n",
    "    value2 = list(entity_dict.values())[0][1]\n",
    "    Bool1 = dflist['title'].str.contains(value1)\n",
    "    Bool2 = dflist['title'].str.contains(value2)\n",
    "    df1 = dflist[Bool1]\n",
    "    df2 = dflist[Bool2]\n",
    "    # print(df1.title)\n",
    "    # print(df2.title)\n",
    "    value1 = list(entity_dict.values())[1]\n",
    "    Bool = df1['title'].str.contains(value1[0])\n",
    "  \n",
    "    for value in entity_dict.values(): \n",
    "#       Bool1 = df1['title'].str.contains(value[0]) | df1['specs'].str.contains(value[0])\n",
    "      Bool1 = df1['title'].str.contains(value[0])\n",
    "      Bool1 = (Bool & Bool1)\n",
    "      Bool = Bool1\n",
    "    \n",
    "    df11 = df1[Bool]\n",
    "    \n",
    "    value2 = list(entity_dict.values())[1]\n",
    "    print(value2)\n",
    "    Bool = df2['title'].str.contains(value2[1])\n",
    "    # print(df11)\n",
    "    # print('2nd')\n",
    "    for value in entity_dict.values(): \n",
    "      # if(value not in value2[0] ):\n",
    "#         Bool1 = df2['title'].str.contains(value[0]) | df2['specs'].str.contains(value[0])\n",
    "        Bool1 = df2['title'].str.contains(value[0])\n",
    "        Bool1 = (Bool | Bool1)\n",
    "        Bool = Bool1\n",
    "    # print(Bool)\n",
    "    df22 = df2[Bool]\n",
    "    #print(df22)\n",
    "#     print('Dorami: Product 1 specs', df11.title , df11.specs , df11.price, sep='\\n' )\n",
    "#     print('Dorami: Product 2 specs', df22.title , df22.specs , df22.price , sep='\\n' )\n",
    "    return [('Dorami: Product 1 specs', df11.title , df11.price), ('Dorami: Product 2 specs', df22.title, df22.price)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_intents = []\n",
    "past_entities = []\n",
    "past_entity_dict = dict()\n",
    "a = None\n",
    "b = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res={}\n",
    "# res['data']='The price of the requested products are shown below:-'\n",
    "# res['title']=[\"a\",\"b\"]\n",
    "# res['price']=[3,4]\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(user_query):\n",
    "    try:\n",
    "        # initializing the dictionary containing results to be returned to the frontend\n",
    "        res = dict()\n",
    "        \n",
    "        # capturing intents and entities\n",
    "        intent, entity_dict = intents_ent(user_query)\n",
    "#         print(intent, entity_dict)\n",
    "        \n",
    "        \n",
    "        # to capture missing product name in comparison info search\n",
    "        if past_intents != [] and past_intents[-1] == 'Comparison_info':\n",
    "            past_entity_dict = past_entities[-1]\n",
    "            past_entity_dict.update(entity_dict)\n",
    "            res['data'] = comp_search(past_entity_dict)\n",
    "            return res\n",
    "\n",
    "\n",
    "#         # for missing_entity function\n",
    "#         if a == \"missing_ent\":\n",
    "#             if intent == \"no\":\n",
    "#                 #print('Dorami: These are the products I found based on your specifications, is this what you are looking for?', query_df.title, sep='\\n')\n",
    "#                 a = None\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 past_entity_dict.update(entity_dict)\n",
    "#                 entity_dict = past_entity_dict.copy()\n",
    "\n",
    "#         # just to check if code capturing right intents and entitites\n",
    "#        # print(intent,entity_dict)\n",
    "\n",
    "#         # when Dorami asks the user more details to narrow the search results\n",
    "#         if past_intents != [] and past_intents[-1] == 'Buy_info':\n",
    "#           #print(past_intents[-1] )\n",
    "#           past_entity_dict = past_entities[-1]\n",
    "#           past_entity_dict.update(entity_dict)\n",
    "#           if 'brand' not in past_entity_dict.keys() and b != 'brand':\n",
    "#               res['data'] = missing_entity('brand', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#               b = 'brand'\n",
    "#               return res\n",
    "#     #           past_entity_dict.update(missing_entity_dict)\n",
    "#           if 'product_name' not in past_entity_dict.keys():\n",
    "#               res['data'] = missing_entity('product_name', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#     #           past_entity_dict.update(missing_entity_dict)\n",
    "#           if 'colour' not in past_entity_dict.keys():\n",
    "#               res['data'] = missing_entity('colour', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#     #           past_entity_dict.update(missing_entity_dict)\n",
    "\n",
    "#           # appending spec_info intent at the end of intents list to avoid going into this if clause again in the next chatbot func iteration\n",
    "#           past_intents.append('spec_info')\n",
    "#     #       return(past_entity_dict)\n",
    "#     #      print(past_entity_dict)\n",
    "#           query_df = sql_search(past_entity_dict)\n",
    "#     #       return('Dorami: These are the products I found based on your specifications, is this what you are looking for?', query_df.title, sep='\\n')\n",
    "#           p=('Dorami: These are the products I found based on your specifications, is this what you are looking for?', query_df.title)\n",
    "#           res.append(p)\n",
    "#           return res\n",
    "\n",
    "        # when Dorami asks the user more details to narrow the search results\n",
    "        \n",
    "#         if past_intents != [] and (past_intents[-1] == 'Buy_info' or past_intents[-1] == 'similar_product') and intent not in ['Bye', 'yes', 'Q_A', 'Price_info', 'similar_product', 'Comparison_info']:\n",
    "#             print(past_intents[-1])\n",
    "#             past_entity_dict = past_entities[-1]\n",
    "#             past_entity_dict.update(entity_dict)\n",
    "#             if 'product_type' not in past_entity_dict.keys():\n",
    "#                 # for now since we are only dealing in laptops\n",
    "#                 past_entity_dict['product_type'] = 'laptop'\n",
    "#             if 'brand' not in past_entity_dict.keys():\n",
    "#                 res['data'] = missing_entity('brand', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#             if 'product_name' not in past_entity_dict.keys():\n",
    "#                 res['data'] = missing_entity('product_name', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#             if 'colour' not in past_entity_dict.keys():\n",
    "#                 res['data'] = missing_entity('colour', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "\n",
    "#           # appending _ intent at the end of intents list to avoid going into this if clause again in the next chatbot func iteration\n",
    "# #             past_intents.append('_')\n",
    "# #             past_entities.append(past_entity_dict)\n",
    "# #             print(past_entity_dict)\n",
    "\n",
    "# #             query_df = sql_search(past_entity_dict)\n",
    "# #             print('Dorami: These are the products I found based on your specifications, is this what you are looking for?', query_df.title, sep='\\n')\n",
    "            \n",
    "\n",
    "#         if past_intents != [] and (past_intents[-2] == 'Buy_info' or past_intents[-2] == 'similar_product') and 'brand' in list(entity_dict.keys()):\n",
    "#             past_entity_dict.update(entity_dict)\n",
    "        \n",
    "#         if past_intents != [] and (past_intents[-3] == 'Buy_info' or past_intents[-3] == 'similar_product') and 'product_name' in list(entity_dict.keys()):\n",
    "#             past_entity_dict.update(entity_dict) \n",
    "            \n",
    "#         if past_intents != [] and (past_intents[-4] == 'Buy_info' or past_intents[-4] == 'similar_product') and 'colour' in list(entity_dict.keys()):\n",
    "#             past_entity_dict.update(entity_dict)\n",
    "#             res['data'] = sql_search(past_entity_dict)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    #     # when Dorami asks the user more details to narrow the search results\n",
    "    #     elif len(past_intents) > 1 and (past_intents[-2] == 'Buy_info' or past_intents[-2] == 'similar_product') and intent not in ['Bye', 'yes']:\n",
    "    #       print(past_intents[-2] )\n",
    "    #       past_entity_dict = past_entities[-2]\n",
    "    #       past_entity_dict.update(entity_dict)\n",
    "    #       if 'product_type' not in past_entity_dict.keys():\n",
    "    #           past_entity_dict['product_type'] = 'laptop'\n",
    "    #       if 'brand' not in past_entity_dict.keys():\n",
    "    #           missing_entity_dict = missing_entity('brand', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "    #           past_entity_dict.update(missing_entity_dict)\n",
    "    #       if 'product_name' not in past_entity_dict.keys():\n",
    "    #           missing_entity_dict = missing_entity('product_name', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "    #           past_entity_dict.update(missing_entity_dict)\n",
    "    #       if 'colour' not in past_entity_dict.keys():\n",
    "    #           missing_entity_dict = missing_entity('colour', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "    #           past_entity_dict.update(missing_entity_dict)\n",
    "\n",
    "    #       # appending spec_info intent at the end of intents list to avoid going into this if clause again in the next chatbot func iteration\n",
    "    #       past_intents.append('_')\n",
    "    #       past_entities.append(past_entity_dict)\n",
    "    #       print(past_entity_dict)\n",
    "\n",
    "    #       query_df = sql_search(past_entity_dict)\n",
    "    #       print('Dorami: These are the products I found based on your specifications, is this what you are looking for?', query_df.title, sep='\\n')\n",
    "    #       chatbot()\n",
    "\n",
    "        # storing the intents and entities for use in above scenario and dialogue context tracking\n",
    "        past_intents.append(intent)\n",
    "        past_entities.append(entity_dict)\n",
    "\n",
    "\n",
    "        # q_a intent\n",
    "        if intent == 'Q_A':\n",
    "            res['data'] = Q_A(user_query)\n",
    "            return res\n",
    "\n",
    "\n",
    "        # buy_info\n",
    "        elif intent == 'Buy_info':\n",
    "            flag = 0\n",
    "            if 'laptop' in entity_dict['product_type']:\n",
    "                # print(entity_dict)\n",
    "    #             dict_ents_iterable = ['price','size','ram','weight']\n",
    "    #             for entity in dict_ents_iterable:\n",
    "\n",
    "\n",
    "                if 'price_category' in entity_dict:\n",
    "                    flag += 1\n",
    "    #                 print(\"t57\")\n",
    "                    if 'price_above' in entity_dict['price_category']:\n",
    "                      price_cap_int = ''.join(filter(lambda i: i.isdigit(), entity_dict['price'][0]))\n",
    "    #                   print(\"t57\")\n",
    "    #                   print(price_cap_int) \n",
    "    #                   print(entity_dict)\n",
    "                      entity_dict.pop('price')\n",
    "                      entity_dict.pop('price_category')\n",
    "    #                   print(entity_dict)\n",
    "                      dfprice = sql_search(entity_dict)\n",
    "    #                   print(dfprice)\n",
    "                      res['data']='The price of the requested products are shown below:-'\n",
    "                      res['title']=[]\n",
    "                      res['entity']=[] \n",
    "                      # for row in dfprice:\n",
    "    #                   print(res)\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "    #                         print('yoooooo')    \n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[5]))\n",
    "    #                     print(price_dat_int)\n",
    "                        if price_dat_int > price_cap_int:\n",
    "    #                       print(\"yes+++\")\n",
    "            #               return(series[0],series[3])\n",
    "    #                       print(series[0],series[3])\n",
    "                          res['title'].append(series[2])\n",
    "                          res['entity'].append(series[5])\n",
    "                        #  print(series[0],series[3+dict_ents_iterable.index(entity)])\n",
    "                        #chatbot()\n",
    "                    elif ('price_below') in entity_dict['price_category']:\n",
    "                      price_cap_int = ''.join(filter(lambda i: i.isdigit(), entity_dict['price'][0]))\n",
    "    #                   print(price_cap_int)\n",
    "                      entity_dict.pop('price')\n",
    "                      entity_dict.pop('price_category')\n",
    "                      # print(entity_dict)\n",
    "                      dfprice = sql_search(entity_dict)\n",
    "                      res['data']='The price of the requested products are shown below:-'\n",
    "                      res['title']=[]\n",
    "                      res['entity']=[]\n",
    "                      # for row in dfprice:\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[5]))\n",
    "    #                     print(price_dat_int)\n",
    "                        if price_dat_int < price_cap_int:\n",
    "            #               return(series[0],series[3])\n",
    "                          res['title'].append(series[2])\n",
    "                          res['entity'].append(series[5])\n",
    "                    elif ('price_around') in entity_dict['price_category']:\n",
    "                      print(\"t59\")\n",
    "                      t = 0\n",
    "                      price_cap_int = ''.join(filter(lambda i: i.isdigit(), entity_dict['price'][0]))\n",
    "                      entity_dict.pop('price')\n",
    "                      entity_dict.pop('price_category')\n",
    "                      # print(entity_dict)\n",
    "                      dfprice = sql_search(entity_dict)\n",
    "                      res['data']='The price of the requested products are shown below:-'\n",
    "                      res['title']=[]\n",
    "                      res['entity']=[]\n",
    "                      prod_ar = []\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[5]))\n",
    "                        if abs(int(price_dat_int) - int(price_cap_int))<abs(int(t)-int(price_cap_int)):\n",
    "                          t = price_dat_int\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[5]))\n",
    "                        if t == price_dat_int:\n",
    "                          res['title'].append(series[2])\n",
    "                          res['entity'].append(series[5])\n",
    "\n",
    "                    elif ('price_range') in entity_dict['price_category']:\n",
    "                      a = ''.join(filter(lambda i: i.isdigit(), entity_dict['price'][0]))\n",
    "                      b = ''.join(filter(lambda i: i.isdigit(), entity_dict['price'][1]))\n",
    "                      price_cap_int_low = min(a,b)\n",
    "                      price_cap_int_high = max(a,b)\n",
    "                      entity_dict.pop('price')\n",
    "                      entity_dict.pop('price_category')\n",
    "                      # print(entity_dict)\n",
    "                      dfprice = sql_search(entity_dict)\n",
    "                      res['data']='The price of the requested products are shown below:-'\n",
    "                      res['title']=[]\n",
    "                      res['entity']=[]\n",
    "                      # for row in dfprice:\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[5]))\n",
    "                        if price_cap_int_low <price_dat_int < price_cap_int_high:\n",
    "            #               return(series[0],series[3])\n",
    "                          res['title'].append(series[2])\n",
    "                          res['entity'].append(series[5])\n",
    "\n",
    "\n",
    "                elif ('size_category') in entity_dict:\n",
    "                    flag += 1\n",
    "                    print(\"t58\")\n",
    "                    if ('size_above') in entity_dict['size_category']:\n",
    "                      price_cap_int = ''.join(filter(lambda i: i.isdigit(), entity_dict['size'][0]))\n",
    "                      print(\"t58\")\n",
    "                      entity_dict.pop('size')\n",
    "                      entity_dict.pop('size_category')\n",
    "    #                       print(entity_dict)\n",
    "                      dfprice = sql_search(entity_dict)\n",
    "                      res['data']='The price of the requested products are shown below:-'\n",
    "                      res['title']=[]\n",
    "                      res['entity']=[] \n",
    "                      # for row in dfprice:\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "    #                         print('yoooooo')    \n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[6]))\n",
    "    #                         print(price_dat_int)\n",
    "                        if price_dat_int > price_cap_int:\n",
    "            #               return(series[0],series[3])\n",
    "                          res['title'].append(series[2])\n",
    "                          res['entity'].append(series[6])\n",
    "                        #  print(series[0],series[3+dict_ents_iterable.index(entity)])\n",
    "                        #chatbot()\n",
    "                    elif ('size_below') in entity_dict['size_category']:\n",
    "                      price_cap_int = ''.join(filter(lambda i: i.isdigit(), entity_dict['size'][0]))\n",
    "                      print(\"t58\")\n",
    "    #                   print(price_cap_int)\n",
    "                      entity_dict.pop('size')\n",
    "                      entity_dict.pop('size_category')\n",
    "                      # print(entity_dict)\n",
    "                      dfprice = sql_search(entity_dict)\n",
    "                      res['data']='The price of the requested products are shown below:-'\n",
    "                      res['title']=[]\n",
    "                      res['entity']=[]\n",
    "                      # for row in dfprice:\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[6]))\n",
    "    #                     print(price_dat_int)\n",
    "                        if price_dat_int < price_cap_int:\n",
    "            #               return(series[0],series[3])\n",
    "                          res['title'].append(series[2])\n",
    "                          res['entity'].append(series[6])\n",
    "                    elif ('size_around') in entity_dict['size_category']:\n",
    "                      t = 0\n",
    "                      price_cap_int = ''.join(filter(lambda i: i.isdigit(), entity_dict['size'][0]))\n",
    "                      entity_dict.pop('size')\n",
    "                      entity_dict.pop('size_category')\n",
    "                      # print(entity_dict)\n",
    "                      dfprice = sql_search(entity_dict)\n",
    "                      res['data']='The price of the requested products are shown below:-'\n",
    "                      res['title']=[]\n",
    "                      res['entity']=[]\n",
    "                      prod_ar = []\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[6]))\n",
    "                        if abs(int(price_dat_int) - int(price_cap_int))<abs(int(t)-int(price_cap_int)):\n",
    "                          t = price_dat_int\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[6]))\n",
    "                        if t == price_dat_int:\n",
    "                            res['title'].append(series[2])\n",
    "                            res['entity'].append(series[6])\n",
    "    #                         print(prod_ar)\n",
    "    #                         res['title'].append(series[0])\n",
    "    #                         res['entity'].append(series[4])\n",
    "\n",
    "                    elif ('size_range') in entity_dict['size_category']:\n",
    "                      a = ''.join(filter(lambda i: i.isdigit(), entity_dict['size'][0]))\n",
    "                      b = ''.join(filter(lambda i: i.isdigit(), entity_dict['size'][1]))\n",
    "                      price_cap_int_low = min(a,b)\n",
    "                      price_cap_int_high = max(a,b)\n",
    "                      entity_dict.pop('size')\n",
    "                      entity_dict.pop('size_category')\n",
    "                      # print(entity_dict)\n",
    "                      dfprice = sql_search(entity_dict)\n",
    "                      res['data']='The price of the requested products are shown below:-'\n",
    "                      res['title']=[]\n",
    "                      res['entity']=[]\n",
    "                      # for row in dfprice:\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[6]))\n",
    "                        if price_cap_int_low <price_dat_int < price_cap_int_high:\n",
    "            #               return(series[0],series[3])\n",
    "                          res['title'].append(series[2])\n",
    "                          res['entity'].append(series[6])\n",
    "\n",
    "\n",
    "\n",
    "                elif ('ram_category') in entity_dict:\n",
    "                    flag += 1\n",
    "                    print(\"t58\")\n",
    "                    if ('ram_above') in entity_dict['ram_category']:\n",
    "                      price_cap_int = ''.join(filter(lambda i: i.isdigit(), entity_dict['ram'][0]))\n",
    "                      print(\"t58\")\n",
    "                      entity_dict.pop('ram')\n",
    "                      entity_dict.pop('ram_category')\n",
    "    #                       print(entity_dict)\n",
    "                      dfprice = sql_search(entity_dict)\n",
    "                      res['data']='The price of the requested products are shown below:-'\n",
    "                      res['title']=[]\n",
    "                      res['entity']=[] \n",
    "                      # for row in dfprice:\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "    #                         print('yoooooo')    \n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[7]))\n",
    "    #                         print(price_dat_int)\n",
    "                        if price_dat_int > price_cap_int:\n",
    "            #               return(series[0],series[3])\n",
    "                          res['title'].append(series[2])\n",
    "                          res['entity'].append(series[7])\n",
    "                        #  print(series[0],series[3+dict_ents_iterable.index(entity)])\n",
    "                        #chatbot()\n",
    "                    elif ('ram_below') in entity_dict['ram_category']:\n",
    "                      price_cap_int = ''.join(filter(lambda i: i.isdigit(), entity_dict['ram'][0]))\n",
    "                      print(\"t58\")\n",
    "    #                   print(price_cap_int)\n",
    "                      entity_dict.pop('ram')\n",
    "                      entity_dict.pop('ram_category')\n",
    "                      # print(entity_dict)\n",
    "                      dfprice = sql_search(entity_dict)\n",
    "                      res['data']='The price of the requested products are shown below:-'\n",
    "                      res['title']=[]\n",
    "                      res['entity']=[]\n",
    "                      # for row in dfprice:\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[7]))\n",
    "    #                     print(price_dat_int)\n",
    "                        if price_dat_int < price_cap_int:\n",
    "            #               return(series[0],series[3])\n",
    "                          res['title'].append(series[2])\n",
    "                          res['entity'].append(series[7])\n",
    "                    elif ('ram_around') in entity_dict['ram_category']:\n",
    "                      t = 0\n",
    "                      price_cap_int = ''.join(filter(lambda i: i.isdigit(), entity_dict['ram'][0]))\n",
    "                      entity_dict.pop('ram')\n",
    "                      entity_dict.pop('ram_category')\n",
    "                      # print(entity_dict)\n",
    "                      dfprice = sql_search(entity_dict)\n",
    "                      res['data']='The price of the requested products are shown below:-'\n",
    "                      res['title']=[]\n",
    "                      res['entity']=[]\n",
    "                      prod_ar = []\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[7]))\n",
    "                        if abs(int(price_dat_int) - int(price_cap_int))<abs(int(t)-int(price_cap_int)):\n",
    "                          t = price_dat_int\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[7]))\n",
    "                        if t == price_dat_int:\n",
    "                            prod_ar.append(series[2])\n",
    "                            prod_ar.append(series[7])\n",
    "                            print(prod_ar)\n",
    "    #                         res['title'].append(series[0])\n",
    "    #                         res['entity'].append(series[4])\n",
    "\n",
    "                    elif ('ram_range') in entity_dict['ram_category']:\n",
    "                      a = ''.join(filter(lambda i: i.isdigit(), entity_dict['ram'][0]))\n",
    "                      b = ''.join(filter(lambda i: i.isdigit(), entity_dict['ram'][1]))\n",
    "                      price_cap_int_low = min(a,b)\n",
    "                      price_cap_int_high = max(a,b)\n",
    "                      entity_dict.pop('ram')\n",
    "                      entity_dict.pop('ram_category')\n",
    "                      # print(entity_dict)\n",
    "                      dfprice = sql_search(entity_dict)\n",
    "                      res['data']='The price of the requested products are shown below:-'\n",
    "                      res['title']=[]\n",
    "                      res['entity']=[]\n",
    "                      # for row in dfprice:\n",
    "                      for (row,series) in dfprice.iterrows():\n",
    "                        price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[7]))\n",
    "                        if price_cap_int_low <price_dat_int < price_cap_int_high:\n",
    "            #               return(series[0],series[3])\n",
    "                          res['title'].append(series[2])\n",
    "                          res['entity'].append(series[7])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if(flag>0):              \n",
    "                    return res\n",
    "\n",
    "                else:\n",
    "                    dfprice = sql_search(entity_dict)\n",
    "                    res['title']=[]\n",
    "                    res[\"data\"] = ' These are all the'\n",
    "                    for key in entity_dict.keys():\n",
    "                        res[\"data\"] += ' ' + entity_dict[key][0]\n",
    "                    res[\"data\"] += ' in our catalogue. You can choose any one of them or even give me more specifications that you want so I can narrow down the results for you!'\n",
    "            #           return(output, query_df.title, sep='\\n')\n",
    "                    for (row,series) in dfprice.iterrows():\n",
    "                        res['title'].append(series[2])\n",
    "                    return res\n",
    "\n",
    "\n",
    "        # greetings intent\n",
    "        elif intent == 'Greetings':\n",
    "            res['data'] = 'Hello, I am Dorami. How can I help you?'\n",
    "            return res\n",
    "\n",
    "        \n",
    "        # price_info intent\n",
    "        elif intent == 'Price_info':\n",
    "            dfnew = sql_search(entity_dict)\n",
    "            res['data'] = 'The price of the requested products are shown below:-'\n",
    "            res['title'] = []\n",
    "            res['price'] = []\n",
    "            for (row,series) in dfnew.iterrows():\n",
    "                res['title'].append(series[2])\n",
    "                res['price'].append(series[5])\n",
    "            return res\n",
    "\n",
    "\n",
    "        # bye intent\n",
    "        elif intent == 'Bye':\n",
    "            if len(past_intents) > 1 and past_intents[-2] == 'Buy_info':\n",
    "                res['data'] = 'Great, I am glad you  like the products, do let me further technical specifications in which you want the product or you can just select any of the above products'\n",
    "            else:\n",
    "                replies = ['Goodbye and have a nice day!', 'Arigato Gozaimashita, Have a great day ahead!', 'Thankyou for shopping, have a fine day!']\n",
    "                res['data'] = random.choice(replies)\n",
    "            return res\n",
    "\n",
    "\n",
    "        # yes intent\n",
    "        elif intent == 'yes':\n",
    "            res['data'] = 'I am happy that this is what you want!!'\n",
    "            return res\n",
    "\n",
    "\n",
    "        # no intent\n",
    "        elif intent == 'no':\n",
    "            replies = ['If you want any specific product you can provide me more details such as the specific brand name, product name or technical specifications too',\n",
    "                      'I am sorry you did not like the products, you can chose to give me more details or contact Otsuka Shokai Sales for further inquiry',\n",
    "                      'I am sorry you did not like the products I showed, can I know some more details about the kind of product you wanna see so I can show you better products?']\n",
    "            res['data'] = random.choice(replies)\n",
    "            return res\n",
    "        \n",
    "\n",
    "        # similar product intent\n",
    "        elif intent == 'similar_product':\n",
    "            similar_entity_dict = past_entities[-1].copy()\n",
    "            brands = list(dflist.brand.unique())\n",
    "            similar_entity_dict['brand'] = (random.choice(brands),)\n",
    "            if 'product_name' in similar_entity_dict.keys():\n",
    "                similar_entity_dict.pop('product_name')\n",
    "            query_df = sql_search(similar_entity_dict)\n",
    "            past_entities.append(similar_entity_dict)\n",
    "            res['data'] = ('Dorami: These are some of the products similar to the previous one, have a look!', query_df.title)\n",
    "            return res\n",
    "        \n",
    "\n",
    "        # comparison info intent\n",
    "        elif intent == 'Comparison_info':\n",
    "            if 'product_name' not in entity_dict.keys():\n",
    "                res['data'] = 'What models do you want to compare?'\n",
    "                return res\n",
    "            res['data'] = comp_search(entity_dict)\n",
    "            return res\n",
    "\n",
    "\n",
    "        # spec info intent\n",
    "        if intent == 'Specs_info':\n",
    "          sql_search(entity_dict)\n",
    "          chatbot()\n",
    "\n",
    " \n",
    "    except:\n",
    "        res['data'] = 'I am sorry I did not understand your question, could you please check if your question is correct otherwise try a different question or contact Otsuka Shokai Sales!'\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be at the end of the notebook once ur done with testing\n",
    "past_intents.clear()\n",
    "past_entities.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test():\n",
    "#     input_string = input('User: ')\n",
    "#     res = chatbot(input_string)\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  I want the price of hp omen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Price_info'] {'product_name': ['omen'], 'brand': ['hp']}\n",
      "{'product_name': ['omen'], 'brand': ['hp']}\n",
      "{'data': 'The price of the requested products are shown below:-', 'title': ['hp omen core i7 11th gen - (16 gb/1 tb ssd/windows 10 home/8 gb graphics/nvidia geforce rtx 3070) 16-b0370tx gaming laptop  (16.1 inch, shadow black, 2.32 kg, with ms office)', 'hp omen ryzen 7 octa core 4800h - (16 gb/512 gb ssd/windows 10 home/4 gb graphics/nvidia geforce gtx 1650 ti/144 hz) 15-en0501ax gaming laptop (15.6 inch, mica silver, 2.37 kg)'], 'price': ['₹1,71,990', '₹89,990']}\n"
     ]
    }
   ],
   "source": [
    "# simulates frontend\n",
    "# a = test()\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dorami import chatbot\n",
    "# from flask import Flask, request\n",
    "# app = Flask(__name__)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dorami import chatbot\n",
    "from flask import Flask, request\n",
    "from flask_cors import CORS\n",
    "app = Flask(_name_)\n",
    "CORS(app)\n",
    " \n",
    "# def _init_(self):\n",
    "#     \tself.chatbot = chatbot()\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"POST\"])\n",
    "def hello_name():\n",
    "\tinput_string = request.get_json()['input_string']\n",
    "\tres = chatbot(input_string) # res should be a dict\n",
    "# \tres={\n",
    "# \t\t\"data\": \"These are the laptop\",\n",
    "# \t\t\"title\":[\"HP Pavilion Ryzen 5 Hexa Core 5600H - (8 GB/512 GB SSD/Windows 10/4 GB Graphics/NVIDIA GeForce GTX 1650/144 Hz) 15-ec2004AX Gaming Laptop  (15.6 inch, Shadow Black, 1.98 kg)\",\"ASUS TUF Gaming A17 Ryzen 7 Octa Core 4800H - (16 GB/512 GB SSD/Windows 10 Home/4 GB Graphics/NVIDIA GeForce RTX 3050/144 Hz) FA706IC-HX003T Gaming Laptop  (17.3 inch, Graphite Black, 2.60 kg)\"] ,\n",
    "# \t\t\"price\" : [\"100\",\"200\"] ,\n",
    "# \t\t\"img_url\": [\"https://rukminim1.flixcart.com/image/612/612/kbqu4cw0/computer/q/x/r/hp-original-imaftyzachgrav8f.jpeg?q=70\",\"https://rukminim1.flixcart.com/image/612/612/l3rmzrk0/computer/z/2/c/-original-imagetjyhhtrtkdg.jpeg?q=70\"] ,\n",
    "# \t\t\"title_url\":[\"https://www.flipkart.com/hp-pavilion-ryzen-5-hexa-core-5600h-8-gb-512-gb-ssd-windows-10-4-graphics-nvidia-geforce-gtx-1650-144-hz-15-ec2004ax-gaming-laptop/p/itm98c94bbf9bc20?pid=COMG5GZXPWMGTNWS&lid=LSTCOMG5GZXPWMGTNWSQE9WVW&marketplace=FLIPKART&q=HP+Pavilion+Ryzen+5+Hexa+Core+5600H+-+%288+GB%2F512+GB+SSD%2F...%3B+ASUS+TUF+Gaming+A17+Ryzen+7+Octa+Core+4800H+-+%2816+GB%2F51...%3B+acer+Aspire+7+Core+i5+10th+Gen+-+%288+GB%2F512+GB+SSD%2FWindo...%3B+ASUS+TUF+Gaming+F15+Core+i5+10th+Gen+-+%288+GB%2F512+GB+SSD...&store=search.flipkart.com&srno=s_1_2&otracker=search&otracker1=search&fm=Search&iid=7788951f-4646-47a8-a746-6239f371432a.COMG5GZXPWMGTNWS.SEARCH&ppt=sp&ppn=sp&ssid=xcyp1j9xj40000001656243820753&qH=707549e6ce269adf\",\n",
    "# \t\t\t\t\t\t\"https://www.flipkart.com/asus-tuf-gaming-a17-ryzen-7-octa-core-4800h-16-gb-512-gb-ssd-windows-10-home-4-graphics-nvidia-geforce-rtx-3050-144-hz-fa706ic-hx003t-laptop/p/itmccc79bbd17e07?pid=COMG8N5PFPCX9Z3J&lid=LSTCOMG8N5PFPCX9Z3JGKCEFC&marketplace=FLIPKART&cmpid=content_computer_15083003945_u_8965229628_gmc_pla&tgi=sem,1,G,11214002,u,,,556262839325,,,,c,,,,,,,&gclid=CjwKCAjwh-CVBhB8EiwAjFEPGcxYUKUL4RQPdprBhLDbEgKm7R14pHuY0o73wTzRXQ-amw29uNg3XBoC5mIQAvD_BwE\"]\t\t\n",
    "# \t}\n",
    "\t\n",
    "\treturn res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\tapp.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dflist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test2():\n",
    "#     user_query = input('User: ')\n",
    "#     try:\n",
    "#         # initializing the dictionary containing results to be returned to the frontend\n",
    "#         res = dict()\n",
    "        \n",
    "#         # capturing intents and entities\n",
    "#         intent, entity_dict = intents_ent(user_query)\n",
    "#         print(intent, entity_dict)\n",
    "        \n",
    "        \n",
    "#         # to capture missing product name in comparison info search\n",
    "#         if past_intents != [] and past_intents[-1] == 'Comparison_info':\n",
    "#             past_entity_dict = past_entities[-1]\n",
    "#             past_entity_dict.update(entity_dict)\n",
    "#             res['data'] = comp_search(past_entity_dict)\n",
    "#             return res\n",
    "\n",
    "\n",
    "#     #     # for missing_entity function\n",
    "#     #     if a==\"missing_ent\":\n",
    "#     #         if intent ==\"no\":\n",
    "#     #             #print('Dorami: These are the products I found based on your specifications, is this what you are looking for?', query_df.title, sep='\\n')\n",
    "#     #             a=\"none\"\n",
    "#     #             pass\n",
    "#     #         else:\n",
    "#     #             past_entity_dict.update(entity_dict)\n",
    "#     #             entity_dict=past_entity_dict.copy()\n",
    "\n",
    "#         # just to check if code capturing right intents and entitites\n",
    "#        # print(intent,entity_dict)\n",
    "\n",
    "#     #     # when Dorami asks the user more details to narrow the search results\n",
    "#     #     if past_intents != [] and past_intents[-1] == 'Buy_info':\n",
    "#     #       #print(past_intents[-1] )\n",
    "#     #       past_entity_dict = past_entities[-1]\n",
    "#     #       past_entity_dict.update(entity_dict)\n",
    "#     #       if 'brand' not in past_entity_dict.keys():\n",
    "#     #            missing_entity('brand', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#     # #           past_entity_dict.update(missing_entity_dict)\n",
    "#     #       if 'product_name' not in past_entity_dict.keys():\n",
    "#     #           missing_entity('product_name', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#     # #           past_entity_dict.update(missing_entity_dict)\n",
    "#     #       if 'colour' not in past_entity_dict.keys():\n",
    "#     #           missing_entity('colour', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#     # #           past_entity_dict.update(missing_entity_dict)\n",
    "\n",
    "#     #       # appending spec_info intent at the end of intents list to avoid going into this if clause again in the next chatbot func iteration\n",
    "#     #       past_intents.append('spec_info')\n",
    "#     # #       return(past_entity_dict)\n",
    "#     # #      print(past_entity_dict)\n",
    "#     #       query_df = sql_search(past_entity_dict)\n",
    "#     # #       return('Dorami: These are the products I found based on your specifications, is this what you are looking for?', query_df.title, sep='\\n')\n",
    "#     #       p=('Dorami: These are the products I found based on your specifications, is this what you are looking for?', query_df.title)\n",
    "#     #       res.append(p)\n",
    "#     #       return res\n",
    "\n",
    "#         # when Dorami asks the user more details to narrow the search results\n",
    "#         if past_intents != [] and (past_intents[-1] == 'Buy_info' or past_intents[-1] == 'similar_product') and intent not in ['Bye', 'yes', 'Q_A', 'Price_info', 'similar_product', 'Comparison_info']:\n",
    "#             print(past_intents[-1] )\n",
    "#             past_entity_dict = past_entities[-1]\n",
    "#             past_entity_dict.update(entity_dict)\n",
    "#             if 'product_type' not in past_entity_dict.keys():\n",
    "#                 # for now since we are only dealing in laptops\n",
    "#                 past_entity_dict['product_type'] = 'laptop'\n",
    "#             if 'brand' not in past_entity_dict.keys():\n",
    "#                 missing_entity_dict = missing_entity('brand', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#                 past_entity_dict.update(missing_entity_dict)\n",
    "#             if 'product_name' not in past_entity_dict.keys():\n",
    "#                 missing_entity_dict = missing_entity('product_name', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#                 past_entity_dict.update(missing_entity_dict)\n",
    "#             if 'colour' not in past_entity_dict.keys():\n",
    "#                 missing_entity_dict = missing_entity('colour', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#                 past_entity_dict.update(missing_entity_dict)\n",
    "\n",
    "#           # appending _ intent at the end of intents list to avoid going into this if clause again in the next chatbot func iteration\n",
    "#             past_intents.append('_')\n",
    "#             past_entities.append(past_entity_dict)\n",
    "#             print(past_entity_dict)\n",
    "\n",
    "#             query_df = sql_search(past_entity_dict)\n",
    "#             print('Dorami: These are the products I found based on your specifications, is this what you are looking for?', query_df.title, sep='\\n')\n",
    "#             chatbot()\n",
    "            \n",
    "# #         if past_intents != [] and (past_intents[-2] == 'Buy_info' or past_intents[-2] == 'similar_product') and :\n",
    "# #             pass\n",
    "            \n",
    "\n",
    "#     #     # when Dorami asks the user more details to narrow the search results\n",
    "#     #     elif len(past_intents) > 1 and (past_intents[-2] == 'Buy_info' or past_intents[-2] == 'similar_product') and intent not in ['Bye', 'yes']:\n",
    "#     #       print(past_intents[-2] )\n",
    "#     #       past_entity_dict = past_entities[-2]\n",
    "#     #       past_entity_dict.update(entity_dict)\n",
    "#     #       if 'product_type' not in past_entity_dict.keys():\n",
    "#     #           past_entity_dict['product_type'] = 'laptop'\n",
    "#     #       if 'brand' not in past_entity_dict.keys():\n",
    "#     #           missing_entity_dict = missing_entity('brand', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#     #           past_entity_dict.update(missing_entity_dict)\n",
    "#     #       if 'product_name' not in past_entity_dict.keys():\n",
    "#     #           missing_entity_dict = missing_entity('product_name', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#     #           past_entity_dict.update(missing_entity_dict)\n",
    "#     #       if 'colour' not in past_entity_dict.keys():\n",
    "#     #           missing_entity_dict = missing_entity('colour', past_entity_dict['product_type'][0], past_entity_dict)\n",
    "#     #           past_entity_dict.update(missing_entity_dict)\n",
    "\n",
    "#     #       # appending spec_info intent at the end of intents list to avoid going into this if clause again in the next chatbot func iteration\n",
    "#     #       past_intents.append('_')\n",
    "#     #       past_entities.append(past_entity_dict)\n",
    "#     #       print(past_entity_dict)\n",
    "\n",
    "#     #       query_df = sql_search(past_entity_dict)\n",
    "#     #       print('Dorami: These are the products I found based on your specifications, is this what you are looking for?', query_df.title, sep='\\n')\n",
    "#     #       chatbot()\n",
    "\n",
    "#         # storing the intents and entities for use in above scenario and dialogue context tracking\n",
    "#         past_intents.append(intent)\n",
    "#         past_entities.append(entity_dict)\n",
    "\n",
    "\n",
    "#         # q_a intent\n",
    "#         if intent == 'Q_A':\n",
    "#             res['data'] = Q_A(user_query)\n",
    "#             return res\n",
    "\n",
    "\n",
    "#         # buy_info\n",
    "#         elif intent == 'Buy_info':\n",
    "#             if 'laptop' in entity_dict['product_type']:\n",
    "#                 # print(entity_dict)\n",
    "#                 dict_ents_iterable = ['price','size','ram','weight']\n",
    "#                 for entity in dict_ents_iterable:\n",
    "#                     if str(str(entity)+'_category') in entity_dict:\n",
    "#                         if str(str(entity)+'_above') in entity_dict[str(str(entity)+'_category')]:\n",
    "#                           price_cap_int = ''.join(filter(lambda i: i.isdigit(), entity_dict[str(entity)][0]))\n",
    "#         #                   print(price_cap_int)\n",
    "#                           entity_dict.pop(str((entity)))\n",
    "#                           entity_dict.pop(str(str(entity)+'_category'))\n",
    "#                           # print(entity_dict)\n",
    "#                           dfprice = sql_search(entity_dict)\n",
    "#                           res['data']='The price of the requested products are shown below:-'\n",
    "#                           res['title']=[]\n",
    "#                           res['entity']=[] \n",
    "#                           # for row in dfprice:\n",
    "#                           for (row,series) in dfprice.iterrows():\n",
    "#                             price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[3+dict_ents_iterable.index(entity)]))\n",
    "#         #                     print(price_dat_int)\n",
    "#                             if price_dat_int > price_cap_int:\n",
    "#                 #               return(series[0],series[3])\n",
    "\n",
    "#                               res['title'].append(series[0])\n",
    "#                               res['entity'].append(series[3+dict_ents_iterable.index(entity)])\n",
    "#                             #  print(series[0],series[3+dict_ents_iterable.index(entity)])\n",
    "#                             #chatbot()\n",
    "#                         elif str(str(entity)+'_below') in entity_dict[str(str(entity)+'_category')]:\n",
    "#                           price_cap_int = ''.join(filter(lambda i: i.isdigit(), entity_dict[str(entity)][0]))\n",
    "#         #                   print(price_cap_int)\n",
    "#                           entity_dict.pop(str((entity)))\n",
    "#                           entity_dict.pop(str(str(entity)+'_category'))\n",
    "#                           # print(entity_dict)\n",
    "#                           dfprice = sql_search(entity_dict)\n",
    "#                           # for row in dfprice:\n",
    "#                           for (row,series) in dfprice.iterrows():\n",
    "#                             price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[3+dict_ents_iterable.index(entity)]))\n",
    "#         #                     print(price_dat_int)\n",
    "#                             if price_dat_int < price_cap_int:\n",
    "#                 #               return(series[0],series[3])\n",
    "#                               res['title'].append(series[0])\n",
    "#                               res['entity'].append(series[3+dict_ents_iterable.index(entity)])\n",
    "#                         elif str(str(entity)+'_around') in entity_dict[str(str(entity)+'_category')]:\n",
    "#                           t = 0\n",
    "#                           price_cap_int = ''.join(filter(lambda i: i.isdigit(), entity_dict[str(entity)][0]))\n",
    "#                           entity_dict.pop(str((entity)))\n",
    "#                           entity_dict.pop(str(str(entity)+'_category'))\n",
    "#                           # print(entity_dict)\n",
    "#                           dfprice = sql_search(entity_dict)\n",
    "#                           prod_ar = []\n",
    "#                           for (row,series) in dfprice.iterrows():\n",
    "#                             price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[3+dict_ents_iterable.index(entity)]))\n",
    "#                             if abs(int(price_dat_int) - int(price_cap_int))<abs(int(t)-int(price_cap_int)):\n",
    "#                               t = price_dat_int\n",
    "#                           for (row,series) in dfprice.iterrows():\n",
    "#                             price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[3+dict_ents_iterable.index(entity)]))\n",
    "#                             if t == price_dat_int:\n",
    "#                               res['title'].append(series[0])\n",
    "#                               res['entity'].append(series[3+dict_ents_iterable.index(entity)])\n",
    "\n",
    "#                         elif str(str(entity)+'_range') in entity_dict[str(str(entity)+'_category')]:\n",
    "#                           a = ''.join(filter(lambda i: i.isdigit(), entity_dict[str(entity)][0]))\n",
    "#                           b = ''.join(filter(lambda i: i.isdigit(), entity_dict[str(entity)][1]))\n",
    "#                           price_cap_int_low = min(a,b)\n",
    "#                           price_cap_int_high = max(a,b)\n",
    "#                           entity_dict.pop(str((entity)))\n",
    "#                           entity_dict.pop(str(str(entity)+'_category'))\n",
    "#                           # print(entity_dict)\n",
    "#                           dfprice = sql_search(entity_dict)\n",
    "#                           # for row in dfprice:\n",
    "#                           for (row,series) in dfprice.iterrows():\n",
    "#                             price_dat_int = ''.join(filter(lambda i: i.isdigit(), series[3+dict_ents_iterable.index(entity)]))\n",
    "#                             if price_cap_int_low <price_dat_int < price_cap_int_high:\n",
    "#                 #               return(series[0],series[3])\n",
    "#                               res['title'].append(series[0])\n",
    "#                               res['entity'].append(series[3+dict_ents_iterable.index(entity)])\n",
    "\n",
    "\n",
    "#             else:\n",
    "#                 query_df = sql_search(entity_dict)\n",
    "#                 res[\"data\"] = ' These are all the'\n",
    "#                 for key in entity_dict.keys():\n",
    "#                     res[\"data\"] += ' ' + entity_dict[key][0]\n",
    "#                 res[\"data\"] += ' in our catalogue. You can choose any one of them or even give me more specifications that you want so I can narrow down the results for you!'\n",
    "#         #           return(output, query_df.title, sep='\\n')\n",
    "#             for (row,series) in dfprice.iterrows():\n",
    "#                 res['title'].append(series[0])\n",
    "#             return res\n",
    "\n",
    "\n",
    "#         # greetings intent\n",
    "#         elif intent == 'Greetings':\n",
    "#             res['data'] = 'Hello, I am Dorami. How can I help you?'\n",
    "#             return res\n",
    "\n",
    "        \n",
    "#         # price_info intent\n",
    "#         elif intent == 'Price_info':\n",
    "#             dfnew = sql_search(entity_dict)\n",
    "#             res['data'] = 'The price of the requested products are shown below:-'\n",
    "#             res['title'] = []\n",
    "#             res['price'] = []\n",
    "#             for (row,series) in dfnew.iterrows():\n",
    "#                 res['title'].append(series[0])\n",
    "#                 res['price'].append(series[3])\n",
    "#             return res\n",
    "\n",
    "\n",
    "#         # bye intent\n",
    "#         elif intent == 'Bye':\n",
    "#             if len(past_intents) > 1 and past_intents[-2] == 'Buy_info':\n",
    "#                 res['data'] = 'Great, I am glad you  like the products, do let me further technical specifications in which you want the product or you can just select any of the above products'\n",
    "#             else:\n",
    "#                 replies = ['Goodbye and have a nice day!', 'Arigato Gozaimashita, Have a great day ahead!', 'Thankyou for shopping, have a fine day!']\n",
    "#                 res['data'] = random.choice(replies)\n",
    "#             return res\n",
    "\n",
    "\n",
    "#         # yes intent\n",
    "#         elif intent == 'yes':\n",
    "#             res['data'] = 'I am happy that this is what you want!!'\n",
    "#             return res\n",
    "\n",
    "\n",
    "#         # no intent\n",
    "#         elif intent == 'no':\n",
    "#             replies = ['If you want any specific product you can provide me more details such as the specific brand name, product name or technical specifications too',\n",
    "#                       'I am sorry you did not like the products, you can chose to give me more details or contact Otsuka Shokai Sales for further inquiry',\n",
    "#                       'I am sorry you did not like the products I showed, can I know some more details about the kind of product you wanna see so I can show you better products?']\n",
    "#             res['data'] = random.choice(replies)\n",
    "#             return res\n",
    "        \n",
    "\n",
    "#         # similar product intent\n",
    "#         elif intent == 'similar_product':\n",
    "#             similar_entity_dict = past_entities[-1].copy()\n",
    "#             brands = list(dflist.brand.unique())\n",
    "#             similar_entity_dict['brand'] = (random.choice(brands),)\n",
    "#             if 'product_name' in similar_entity_dict.keys():\n",
    "#                 similar_entity_dict.pop('product_name')\n",
    "#             query_df = sql_search(similar_entity_dict)\n",
    "#             past_entities.append(similar_entity_dict)\n",
    "#             res['data'] = ('Dorami: These are some of the products similar to the previous one, have a look!', query_df.title)\n",
    "#             return res\n",
    "        \n",
    "\n",
    "#         # comparison info intent\n",
    "#         elif intent == 'Comparison_info':\n",
    "#             if 'product_name' not in entity_dict.keys():\n",
    "#                 res['data'] = 'What models do you want to compare?'\n",
    "#                 return res\n",
    "#             res['data'] = comp_search(entity_dict)\n",
    "#             return res\n",
    "\n",
    "\n",
    "#         # spec info intent\n",
    "#         if intent == 'Specs_info':\n",
    "#           sql_search(entity_dict)\n",
    "#           chatbot()\n",
    "\n",
    " \n",
    "#     except:\n",
    "#         res['data'] = 'I am sorry I did not understand your question, could you please check if your question is correct otherwise try a different question or contact Otsuka Shokai Sales!'\n",
    "#         return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = test2()\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this will be at the end of the notebook once ur done with testing\n",
    "# past_intents.clear()\n",
    "# past_entities.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
